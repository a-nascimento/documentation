Day 1
Always use workstation

***
External - 192.168.0.0/24
MGMT - 172.25.250.0/24
***

Power - 192.168.1.0/24

Install Methods:

PackStack - original installer, CLI utilit that leverages Puppet to deploy openstack
	pros
		non-interactive by use of answer files
		replicate config to many hosts
		very easy to use
	cons
		unable to deploy on bare metal
		no API access when used programattically
		does not support multiple controllers so no HA of OpenStack
		No ability to configure other nodes except computer and controllers
		Doesn't allow network isolation with complex topology
		No UI

Undercloud - OpenStack Platform Directory, New install, config, and monitoring toolset for RHOpenStack Platform deployments. Recommend for prod-read platform ready 8 environments
	uses API to install OpenStack
	provides tools to scal the capacity of OpenStack
	Provides central logging tool
	Uses Pacemaker for HA of deployed ENV
	Defines topology and config using HEAT templates (HEAT - template based orchestration tool [will deploy stack according to config template])
	Uses - undercloud / overcloud concepts
		overcloud - defines the instances
		undercloud - Controllers, Computer, Storage nodes

Unit Quiz - pg 4


TripleO Architecture - OpenStack On OpenStack
	deployment and management tool for deployment, config, and automation used by undercloud.
	Creates a prod cloud known as overcloud and the underlying deployment known as undercloud

	Services/Projects:
		Ironic - Provisions physical HW through PXE and IPMI
		Nova - Provisions overcloud nodes like computer, controller, and Ceph storage nodes
		Neutron - Provides networking env
		Glance - repository for images used by ironic for bare-metal provisioning and while deploying overcloud nodes
		Heat - orchestration of overcloud deployment
		Ceilometer - collects metrics about the overcloud nodes
		Cinder - provides volumes needed to deploy the overcloud nodes
		Horizon - Provides the Web UI
		Keystone - provides authentication for overcloud nodes

Unit Quiz - pg 10


Undercloud Backend Services
	Heat - the orchestration service
		Hot - template format for heat, written in YAML (start in OSP 6 - prior to 6 AWS cloud formation was used)
			3 major sections
				Parameters - input parms when deploying from template
				Resources - infrastructure elements to deploy, such as VMs or network ports
				Outputs - output parms dynamically generated by HEAT, e.g. public IP and an instance that has been deployed by the template
	Ironic - the bare metal provisioning service
	RabbitMQ - the messaging service

Unit Quiz - pg 16


Deploying Openstack Cloud
	Deploying overcloud
		Prepare overcloud images - nodes that can be deployed in overcloud
			Controller
			Computer
			Ceph storage - block storage (can provide NFS) and object storage (s3)
			Cinder storage - block storage
			Swift storage - object storage (e.g. s3)

		There are prebuilt images that are required for provisioning the overcloud nodes:
			Discovery kernel and ramdisk: Used during the bare-metal discovery and introspection.
			Deployment kernel and ramdisk: Used for the first stage of provisioning and deployment.
			Overcloud kernel, ramdisk, and full image: Base for each overcloud node created.

Unit Quiz - pg  46

#################################
#################################
#################################
#################################

Day 2

openstack has a unified solution for managing all underlying services leveraging the 'openstack'

Keystone
Managing the Keystone Identity Service


Need to provide these 4 vars for auth - pg 51
export OS_USERNAME=testuser
export OS_PASSWORD=redhat
export OS_PROJECT_NAME=mytestprojectservera
export OS_AUTH_URL=demo:5000/v2.0

Managing OpenStack projects


CH - 3 Managing Flavors

Flavors are the instance types/sizes, etc

Ephemeral storage are temporary disks - they are destroyed when the system reboots (root disks are ephemeral all additional attached disks are also ephemeral)

Cinder volumes are persistenace storage

Ch 4 - Managing Networks

Typically the most complex item to configure
Requires lots and lots of planning
How does OpenStack env. fit into current env?

#################################
#################################
#################################
#################################

Day 3

CH 4 - cont'd
Managing Routers

Leverage 'neutron' command

source /etc/bash_completion.d/neutron.bash_completion
comes packaged with OSP installation


Verifying OpenStack Networking Functionality
Linux namespaces - containerized (and isolated) networks on a Red Hat system - virtualized

TAP devices - virtual network kernel devices - they simulate a link layer device and operate with L2 packets - eg. eth frames - can be used to create network bridges

vEth devices - connect to other virtual network devices; essentially virtual patch cables. In OSP this device can be used to connect the tenant network to the infrastructure network - uses point to point by assigning addresses to both ends and doing routing on the host or by using bridging


CH 5
Managing Floating IP Addresses

Floating IPs managed by Neutron service

open vSwitch - used for L3 networking


# commands for floating IP
openstack ip floating add
openstack ip floating create
openstack ip floating delete
openstack ip floating pool list
openstack ip floating remove


CH 6
Managing Security Groups and Rules


CH 7
Managing Instances
	Launching and Deleting an Instance
	Managing Instances
	Customizing an Instance
		leverages cloud-init - allows for preconfiguration 
		cloud-init leverages YAML syntax - pg 251 example
	Verify Customization
		check cloud-init.log - /var/log

CH 8
Adding Additional Compute Nodes
	Administrators can seamlessly increase or decrease resource capacity of a running overcloud by starting more servers of a selected role (e.g., a compute node or storage node) or by deleting some servers if capacity should be decreased. To add one or more nodes to an OpenStack environment, the following procedure should be used:
		1. The server should be provisioned with a supported operating system, such as Red Hat Enterprise Linux 7.
		2. Administrators should then subscribe the system to the Red Hat Network channel, rhel-7-server-openstack-8.0-rpms.
		3. A file should be created to describe the specifications of the server. The node can be added using openstack baremetal import --json SERVER.jsoncommand.
		4. The introspection for the node can be then initiated, which will allow Ironic to discover the node's capabilities and make it available.
		5. If manual tagging is used, administrators should then tag the node in order to map an existing flavor to this node.
		6. Finally, administrators can scale up their environment by increasing the resource they wish to scale, i.e., a controller node, a storage node, or a compute node.
	Verifying Additional Compute Nodes
	Migrating Instances Between Compute Nodes 

#################################
#################################
#################################
#################################


Day 4

CH 9
Building A Customized Image
	- diskimage-builder: is a tool for customizing cloud images and provides support for building cloud images using Red Hat and Fedora. Diskimage-builder outputs a virtual disk image in a qcow2 format. Elements are applied by diskimage-builder during the build process to customize the image. An element is a code set that runs within a chroot environment and alters how an image is built. For example, the docker elements export a tarball from a named container allowing other elements to build on top of it or the element bootloader, which installs grub2 on the boot partition of the system.
		Architecture
		Elements
		Element Dependencies

	- guestfish: is part of a suite of tools provided by the libguestfs-tools package and is an interactive shell that enables cloud administrators to modify a prebuilt image. Guestfish can be used from the command line and from shell scripts as well. All functionality provided by the libguestfs API is available from the shell.


Verifying an Image (325)


CH 10
Deploying Red Hat OpenStack Platform Director (344)

	Need to install 'TripleO' to deploy

 they used to use: crudini (create, read, update, delete - of ini files)




#################################
#################################
#################################
#################################


Day 5

# Not standard OSP commands - come packaged in Red Hat
openstack-status
openstack-service





parameters:
  public_net: dev_pubnet
  private_net: dev_privnet
  private_subnet: dev_privsub
  key_name: dev_key1
  flavor: m2.small




Heat can be used to scale in and out automagically
Managed by a service called AODH
	create alarms based on system metrics from ceilometer
		cpu
		ram
		network
		etc.




















































